{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEHK10lduCU3"
   },
   "source": [
    "# Finetuning a transformer model for a domain\n",
    "\n",
    "*This notebook must be run on a GPU system with Cuda drivers.*\n",
    "\n",
    "*For many applications, free GPU on [Colab](https://colab.research.google.com) may be enough*.\n",
    "\n",
    "----\n",
    "\n",
    "The aim here is to fine-tune an open-source pre-trained transformer model based on a set of text items that will attune it to perform more effectively on a specific domain. This means that we will be adapting the general capabilities of the model to better suit the needs and nuances of a particular field or area of expertise.\n",
    "\n",
    "Maybe surprisingly, in spite of the huge size of most pre-trained models, the number of domain examples needed to fine-tune it can often be relatively small (see, for example, the widely cited paper on LLMs being ['few-shot learners'](https://arxiv.org/abs/2005.14165)). This is because the transformer models have a robust foundation of general language understanding, and the fine-tuning acts more like a focused nudge, refining what the model already knows, rather than starting training from scratch.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2kPd_nQ02zy"
   },
   "outputs": [],
   "source": [
    "# check that we have cuda\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8XuEObyuCU5"
   },
   "source": [
    "Install `unsloth`. It makes finetuning of transformer models much less resource-intensive. Read more [here](https://huggingface.com/unsloth) and [here](https://unsloth.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eSvM9zX_2d3"
   },
   "outputs": [],
   "source": [
    "!pip install unsloth\n",
    "# also get the latest build of unsloth from GitHub\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JT8JUNmOtePf"
   },
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gonrqNZCtcRg",
    "outputId": "1ef28549-b45a-472a-80a8-be9a5fb1c9f7"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pof_KmYOt1ua"
   },
   "source": [
    "Check over on [unsloth's huggingface profile](https://huggingface.com/unsloth) which models they support. In this case we chose \"`unsloth/mistral-7b-instruct-v0.2-bnb-4bit`\".\n",
    "\n",
    "We download the model. Some notes:\n",
    "\n",
    "- Unsloth supports [RoPE scaling](https://paperswithcode.com/paper/roformer-enhanced-transformer-with-rotary), meaning that the `max_seq_length` can be set much higher than what the model was initially trained on (if one would want to).\n",
    "- Set `dtype = None` for auto detection.\n",
    "- Loading in `4bit` means that the model's weights are quantized to 4 bits, which significantly reduces the memory usage and computational requirements compared to using full precision (usually 16 or 32 bits).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "184bfce2-8193-4f05-de39-5e47010735b7"
   },
   "outputs": [],
   "source": [
    "#model_name =  \"unsloth/Qwen2.5-0.5B-Instruct-bnb-4bit\"\n",
    "model_name = \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\"\n",
    "max_seq_length = 2048\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add [LoRA adapters](https://arxiv.org/abs/2106.09685) so we only need to update 1 to 10% of all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "df9e450e-8f1a-4ad2-b94b-17978238d291"
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "**Finetuning data**: We need a csv file with one column, named 'text', where each row is domain text examples. The example here is 5,000 social media posts about climate change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyGPf9615zVn",
    "outputId": "d222dc58-2b94-4011-d33c-619049403b83"
   },
   "outputs": [],
   "source": [
    "finetuning_file = \"domain.csv\"\n",
    "dataset = load_dataset(\"csv\", data_files=finetuning_file, split=\"train\")\n",
    "\n",
    "# Inspect the dataset\n",
    "print(dataset)\n",
    "print(dataset[0])  # View the first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "82919bc144aa40ac9e09725d5f992155",
      "14f41030f1b94a28abfac8f36b45ea30",
      "af7ff677ca7841b181e464747c67fcb6",
      "87232418270849a09704d282ca4a56ac",
      "954128b14b6347a68ffeddd00d57bf5a",
      "4fac8e510efe4afbbdceb212d60d1e61",
      "58bf85d00cab439188b63642186708f2",
      "b5c05264ae71458693317ecf7b427229",
      "e30f7751774e4996994dcd73ad5ec3ca",
      "3b0f029000944182a38dc676989f6ebc",
      "873b183c804c40a1a4427628fe1d92fa"
     ]
    },
    "id": "95_Nn-89DhsL",
    "outputId": "a44c000d-79ee-42f5-c13b-c4ffcb8ed157"
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_steps = 50,\n",
    "        max_steps = -1, # <-- for a full run\n",
    "        learning_rate = 0.0000005,\n",
    "        num_train_epochs = 1,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 5,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        seed = 3407,\n",
    "        output_dir = \"fine_tuned_model\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhqjSMpU9f8x"
   },
   "source": [
    "During training (below) the `Training Loss` will be printed. Note that when fine-tuning for domain adaptation, as we are doing here, the goal may not be a drastic reduction in training loss. The fine-tuning process may still generate embeddings that align better with the target domain.\n",
    "\n",
    "Especially, in the case of social media research where we often work with messy (and, in this case, also unlabeled) data, it is not necessarily a problem even if the training loss *increases* somewhat.\n",
    "\n",
    "For tasks such as question-answering or classification, the drop in Training Loss during fine-tuning is more crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yqxqAZ7KJ4oL",
    "outputId": "32537129-7a97-43f6-9529-56495eaf609d"
   },
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcJPRVzsEh0d"
   },
   "source": [
    "Save model to disk.\n",
    "\n",
    "This can take quite some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3AkUawTDDBi",
    "outputId": "c1a6f556-3f0c-4de2-b56d-71f8b5723ef4"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained_merged(\"climate-mistral\", tokenizer, save_method = \"merged_4bit_forced\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpWH1tJ8Ey_r"
   },
   "source": [
    "Push model to Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AP6b1pv9EUm6"
   },
   "outputs": [],
   "source": [
    "model.push_to_hub_merged(\"slindgren/climate-mistral\", tokenizer, save_method = \"merged_4bit_forced\", token = \"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\")."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14f41030f1b94a28abfac8f36b45ea30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fac8e510efe4afbbdceb212d60d1e61",
      "placeholder": "​",
      "style": "IPY_MODEL_58bf85d00cab439188b63642186708f2",
      "value": "Map (num_proc=2): 100%"
     }
    },
    "3b0f029000944182a38dc676989f6ebc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fac8e510efe4afbbdceb212d60d1e61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58bf85d00cab439188b63642186708f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82919bc144aa40ac9e09725d5f992155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14f41030f1b94a28abfac8f36b45ea30",
       "IPY_MODEL_af7ff677ca7841b181e464747c67fcb6",
       "IPY_MODEL_87232418270849a09704d282ca4a56ac"
      ],
      "layout": "IPY_MODEL_954128b14b6347a68ffeddd00d57bf5a"
     }
    },
    "87232418270849a09704d282ca4a56ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b0f029000944182a38dc676989f6ebc",
      "placeholder": "​",
      "style": "IPY_MODEL_873b183c804c40a1a4427628fe1d92fa",
      "value": " 4999/4999 [00:01&lt;00:00, 4107.44 examples/s]"
     }
    },
    "873b183c804c40a1a4427628fe1d92fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "954128b14b6347a68ffeddd00d57bf5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7ff677ca7841b181e464747c67fcb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5c05264ae71458693317ecf7b427229",
      "max": 4999,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e30f7751774e4996994dcd73ad5ec3ca",
      "value": 4999
     }
    },
    "b5c05264ae71458693317ecf7b427229": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e30f7751774e4996994dcd73ad5ec3ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
